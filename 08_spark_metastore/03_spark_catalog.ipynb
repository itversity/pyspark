{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Catalog\n",
    "\n",
    "Let us get an overview of Spark Catalog. It is part of `SparkSession` object.\n",
    "* We can permanently or temporarily create tables or views on top of data in a Data Frame.\n",
    "* Metadata such as table names, column names, data types etc for these tables or views will be stored in Metastore. It is also known as catalog which is exposed as part of SparkSession object.\n",
    "* Permanent tables can be grouped into databases in metastore. If not specified, the tables will be created in **default** database.\n",
    "* Let us say `spark` is of type `SparkSession`. There is an attribute as part of `spark` called as catalog and it is of type pyspark.sql.catalog.Catalog.\n",
    "* We can access catalog using `spark.catalog`.\n",
    "* There are several methods that is part of `spark.catalog`. We will explore them in the later topics.\n",
    "* Following are some of the tasks that can be performed using `spark.catalog` object.\n",
    "  * Check current database and switch to different databases.\n",
    "  * Create permanent table in metastore.\n",
    "  * Create or drop temporary views.\n",
    "  * Register functions.\n",
    "* All the above tasks can be performed using SQL style commands passed to `spark.sql`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
